{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Loading and Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pandas library\n",
    "import pandas as pd\n",
    "\n",
    "# Load sales and supermarket data\n",
    "sales_df = pd.read_csv(r\"C:\\Users\\09sra\\Downloads\\Data Science and Engineering Assignment Datasets\\Data Sciene Internship Assignment Datasets\\sales.csv\")\n",
    "sm_df = pd.read_csv(r\"C:\\Users\\09sra\\Downloads\\Data Science and Engineering Assignment Datasets\\Data Sciene Internship Assignment Datasets\\supermarkets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming to reduce ambiguity \n",
    "sm_df = sm_df.rename(columns={'supermarket_No': 'supermarket'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining sales and supermarket data using left-join\n",
    "merged_df = pd.merge(sales_df, sm_df, on='supermarket', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregating the data into week level for each supermarket\n",
    "weekly_store_df = merged_df.groupby(['supermarket', 'week'], as_index=False).agg({\n",
    "    'amount': 'sum',        # Total amount generated each week        \n",
    "    'units': 'sum',         # No of Units Sold in Total\n",
    "    'basket': 'nunique',    # Total unique Number of Transcations\n",
    "    'voucher': 'sum',       # No of Vouchers used\n",
    "    'province': 'first',    \n",
    "    'postal-code': 'first'   \n",
    "})\n",
    "\n",
    "# Rename column names \n",
    "weekly_store_df.rename(columns={\n",
    "    'amount': 'total_revenue',\n",
    "    'units': 'total_units',\n",
    "    'basket': 'num_transactions',\n",
    "    'voucher': 'total_vouchers'\n",
    "}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by supermarket and week for time-series Analysis \n",
    "weekly_store_df = weekly_store_df.sort_values(['supermarket', 'week'])\n",
    "\n",
    "# Next week's revenue as the target value label \n",
    "weekly_store_df['future_revenue'] = weekly_store_df.groupby('supermarket')['total_revenue'].shift(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed rows which has no future revenue generated \n",
    "weekly_store_df = weekly_store_df.dropna(subset=['future_revenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Lagged Features\n",
    "\n",
    "weekly_store_df['revenue_last_week'] = weekly_store_df.groupby('supermarket')['total_revenue'].shift(1)\n",
    "weekly_store_df['units_last_week']   = weekly_store_df.groupby('supermarket')['total_units'].shift(1)\n",
    "weekly_store_df['numtxn_last_week']   = weekly_store_df.groupby('supermarket')['num_transactions'].shift(1)\n",
    "weekly_store_df['totalvouchers_last_week']   = weekly_store_df.groupby('supermarket')['total_vouchers'].shift(1)\n",
    "\n",
    "\n",
    "\n",
    "# fill any new NaN from the lagging with 0\n",
    "weekly_store_df.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test and Train data Splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a cutoff in between test and train \n",
    "train_cutoff = 24\n",
    "# Splitting data into train(from weeks 1-24) and test(from weeks 25-27)  \n",
    "train_df = weekly_store_df[weekly_store_df['week'] <= train_cutoff]\n",
    "test_df  = weekly_store_df[(weekly_store_df['week'] > train_cutoff) & (weekly_store_df['week'] < 28)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define selected features and target \n",
    "feature_cols = [\n",
    "    'total_revenue', 'total_units', 'num_transactions', 'total_vouchers',\n",
    "    'revenue_last_week', 'units_last_week','numtxn_last_week', 'totalvouchers_last_week' \n",
    "]\n",
    "\n",
    "X_train = train_df[feature_cols]\n",
    "y_train = train_df['future_revenue']\n",
    "\n",
    "X_test = test_df[feature_cols]\n",
    "y_test = test_df['future_revenue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traning and Tuning the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n",
      "Best parameters found: {'max_depth': 10, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Best cross-validation R^2 score: 0.5312792019958545\n",
      "Test RMSE: 112.64022492426157\n",
      "Test R^2: 0.26213120559257574\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Define a base Random Forest model\n",
    "base_model = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Set up a hyperparameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create the GridSearchCV object\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_grid=param_grid,\n",
    "    cv=5,                # 5-fold cross-validation\n",
    "    scoring='r2',        # using R^2 as the metric\n",
    "    n_jobs=-1,           # use all available cores\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Fit the grid search on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Output best hyperparameters and corresponding CV score \n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best cross-validation R^2 score:\", grid_search.best_score_)\n",
    "\n",
    "# Use the best estimator from grid search as the final model\n",
    "model = grid_search.best_estimator_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mse**0.5\n",
    "r2   = r2_score(y_test, y_pred)\n",
    "print(\"Test RMSE:\", rmse)\n",
    "print(\"Test R^2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Forecasting Future Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supermarket</th>\n",
       "      <th>week</th>\n",
       "      <th>predicted_revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>141.536061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>251.797437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>265.668832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>259.323485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>221.192839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>192.273156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>211.403721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>260.561531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>170.746882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>237.041508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>3</td>\n",
       "      <td>26</td>\n",
       "      <td>220.411395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>253.422618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>177.168764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>4</td>\n",
       "      <td>25</td>\n",
       "      <td>182.882661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>4</td>\n",
       "      <td>26</td>\n",
       "      <td>174.007190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>205.020463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>280.619179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>323.413873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>403.336248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>344.410378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     supermarket  week  predicted_revenue\n",
       "19             1    24         141.536061\n",
       "20             1    25         251.797437\n",
       "21             1    26         265.668832\n",
       "22             1    27         259.323485\n",
       "43             2    24         221.192839\n",
       "44             2    25         192.273156\n",
       "45             2    26         211.403721\n",
       "46             2    27         260.561531\n",
       "67             3    24         170.746882\n",
       "68             3    25         237.041508\n",
       "69             3    26         220.411395\n",
       "70             3    27         253.422618\n",
       "91             4    24         177.168764\n",
       "92             4    25         182.882661\n",
       "93             4    26         174.007190\n",
       "94             4    27         205.020463\n",
       "115            5    24         280.619179\n",
       "116            5    25         323.413873\n",
       "117            5    26         403.336248\n",
       "118            5    27         344.410378"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prediction of the final 4 weeks( weeks 24-27) from the aggregated data\n",
    "future_weeks_df = weekly_store_df[weekly_store_df['week'] >= 24].copy()\n",
    "future_weeks_df.sort_values(['supermarket','week'], inplace=True)\n",
    "\n",
    "# Create lag features the same way you did for training\n",
    "future_weeks_df['revenue_last_week'] = future_weeks_df.groupby('supermarket')['total_revenue'].shift(1)\n",
    "future_weeks_df['units_last_week'] = future_weeks_df.groupby('supermarket')['total_units'].shift(1)\n",
    "\n",
    "# Fill missing values\n",
    "future_weeks_df.fillna(0, inplace=True)\n",
    "\n",
    "# Select feature columns for the model\n",
    "feature_cols = ['total_revenue', 'total_units', 'num_transactions', 'total_vouchers',\n",
    "    'revenue_last_week', 'units_last_week','numtxn_last_week', 'totalvouchers_last_week' ]\n",
    "X_future = future_weeks_df[feature_cols]\n",
    "\n",
    "# Predict next week's revenue\n",
    "future_weeks_df['predicted_revenue'] = model.predict(X_future)\n",
    "\n",
    "# Now each row in future_weeks_df has predicted_revenue for next week\n",
    "future_weeks_df[['supermarket','week','predicted_revenue']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High-performing supermarkets: [  5  16  17  23  27  32  33  35  40  54  71  91  92  97 103 106 107 109\n",
      " 112 126 135 162 164 172 174 181 184 186 190 193 196 202 215 218 227 234\n",
      " 235 240 241 247 248 259 264 270 271 276 277 280 285 302 307 308 309 316\n",
      " 321 322 324 326 341 353 357 359 364 366 368 371 373 375 378 380 381 383]\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "future_weeks_df['is_high_perf'] = False\n",
    "for t in [25, 26, 27, 28]:\n",
    "    mask_t = (future_weeks_df['week'] == t)\n",
    "    mean_pred = future_weeks_df.loc[mask_t, 'predicted_revenue'].mean()\n",
    "    threshold = 1.25 * mean_pred\n",
    "\n",
    "    future_weeks_df.loc[mask_t, 'is_high_perf'] = (\n",
    "        future_weeks_df.loc[mask_t, 'predicted_revenue'] >= threshold\n",
    "    )\n",
    "\n",
    "# Creating a consecutive_high column where no supermarket has high performing weeks \n",
    "future_weeks_df['consecutive_high'] = False\n",
    "# Sorting the data by supermarket and week to maintain data in chronological way for each Supermarket\n",
    "future_weeks_df = future_weeks_df.sort_values(['supermarket','week'])\n",
    "\n",
    "\n",
    "for sm_id in future_weeks_df['supermarket'].unique():\n",
    "    sm_mask = (future_weeks_df['supermarket'] == sm_id)\n",
    "    sm_data = future_weeks_df.loc[sm_mask].copy().sort_values('week')\n",
    "\n",
    "    is_hp_array = sm_data['is_high_perf'].values  \n",
    "    consecutive_arr = [False] * len(is_hp_array)\n",
    "    # Identifying high performing weeks for the supermarket consecutively\n",
    "    for i in range(1, len(is_hp_array)):\n",
    "        if is_hp_array[i] and is_hp_array[i-1]:\n",
    "            consecutive_arr[i] = True\n",
    "\n",
    "    future_weeks_df.loc[sm_mask, 'consecutive_high'] = consecutive_arr\n",
    "\n",
    "# Final High Performing Supermarkets\n",
    "high_perf_stores = future_weeks_df.loc[future_weeks_df['consecutive_high'],'supermarket'].unique()\n",
    "print(\"High-performing supermarkets:\", high_perf_stores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
